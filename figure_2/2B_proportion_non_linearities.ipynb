{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 2B: Proportion of non-linearities of GDSC-to-PDXE consensus features\n",
    "This notebook supports Fig_2B of the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All list of import is in module_import.py\n",
    "from module_import import *\n",
    "from compute_proportion import compute_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data settings are in data_settings.py\n",
    "from data_settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = read_data(tissues=tissues,\n",
    "                    data_types=[e for e in data_types],\n",
    "                    projects=projects,\n",
    "                    data_sources=data_sources,\n",
    "                    folder_basis='../data/')\n",
    "\n",
    "source_data_key, target_data_key = reformat_df(data_df, source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library size normalization\n",
    "average_depth_global = 10**5\n",
    "for ds in list(data_df.keys()):\n",
    "    GE_normalized = library_size_normalization.TMM_normalization(data_df[ds].values.astype(float))\n",
    "    GE_normalized = np.array(GE_normalized)\n",
    "    average_depths = np.mean(np.sum(GE_normalized,1))\n",
    "    GE_normalized = GE_normalized / average_depths * average_depth_global\n",
    "    GE_normalized = np.log(np.array(GE_normalized)+1)\n",
    "    data_df[ds] = pd.DataFrame(GE_normalized,\n",
    "                               columns=data_df[ds].columns,\n",
    "                               index=data_df[ds].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "with_mean = True\n",
    "with_std = True\n",
    "\n",
    "normalized_data_df = {\n",
    "    ds : StandardScaler(with_mean=with_mean, with_std=with_std).fit_transform(data_df[ds])\n",
    "    for ds in data_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing contribution of each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_pc = {\n",
    "    'source': 70,\n",
    "    'target': 50\n",
    "}\n",
    "\n",
    "n_pv = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_values = np.logspace(-6,-2,20,base=10)\n",
    "\n",
    "contribution = {gamma:compute_proportion(gamma,\n",
    "                                         number_pc,\n",
    "                                         n_pv,\n",
    "                                         normalized_data_df,\n",
    "                                         source_data_key,\n",
    "                                         target_data_key) for gamma in gamma_values}\n",
    "clf = {gamma:contribution[gamma][0] for gamma in gamma_values}\n",
    "contribution = {gamma:contribution[gamma][1] for gamma in gamma_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the results\n",
    "features = ['offset', 'linear', 'interaction']\n",
    "global_contribution_source = {}\n",
    "global_contribution_target = {}\n",
    "global_contribution_consensus = {}\n",
    "\n",
    "for gamma in gamma_values:\n",
    "    contribution_source = {f:contribution[gamma][f]['source'] for f in features}\n",
    "    global_contribution_source[gamma] = {f:np.mean(contribution_source[f]) for f in contribution_source}\n",
    "\n",
    "    contribution_target = {f:contribution[gamma][f]['target'] for f in features}\n",
    "    global_contribution_target[gamma] = {f:np.mean(contribution_target[f]) for f in contribution_target}\n",
    "\n",
    "    contribution_consensus = {f:contribution[gamma][f]['consensus'] for f in features}\n",
    "    global_contribution_consensus[gamma] = {f:np.mean(contribution_consensus[f]) for f in contribution_consensus}\n",
    "\n",
    "global_contribution_consensus_df = pd.DataFrame(global_contribution_consensus).T\n",
    "global_contribution_consensus_df['higher order'] = (1 - np.sum(global_contribution_consensus_df, axis=1)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks_lines = [\n",
    "    10**(-5),\n",
    "    10**(-4.5),\n",
    "    10**(-4),\n",
    "    10**(-3.5),\n",
    "    10**(-3),\n",
    "    10**(-2.5),\n",
    "    10**(-2),\n",
    "]\n",
    "\n",
    "xticks_lines_labels = [\n",
    "    '\\n%s'%(f'{x:.0E}')\n",
    "    for i, x in enumerate(xticks_lines)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xticks = np.logspace(-5, -2, 4)\n",
    "xticks = np.array(xticks_lines)\n",
    "yticks = np.linspace(0,1,6)\n",
    "yticks_labels = ['%s%%'%(int(100*(y))) for y in yticks]\n",
    "\n",
    "plt.figure(figsize=(17,8.2))\n",
    "\n",
    "plt.stackplot(global_contribution_consensus_df.index.astype(float),\n",
    "              global_contribution_consensus_df.values.T, \n",
    "              labels=global_contribution_consensus_df.columns,alpha=0.75)\n",
    "\n",
    "for i, (x, x_lab) in enumerate(zip(xticks_lines, xticks_lines_labels)):\n",
    "    plt.vlines(x, 0, 1, linewidth=3)\n",
    "\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1), fontsize=15, ncol=2)\n",
    "plt.xscale('log')\n",
    "plt.xticks(0.8*xticks, xticks_lines_labels, fontsize=30, rotation='vertical', color='black')\n",
    "plt.grid(True)\n",
    "plt.yticks(yticks, yticks_labels, fontsize=25)\n",
    "plt.xlim(min(xticks)*.3, xticks[-1]*1.2)\n",
    "plt.ylim(0,1.01)\n",
    "plt.ylabel('Geometric proportion \\n of linear and non-linear terms \\n in consensus features',\n",
    "           fontsize=30,\n",
    "           color='black')\n",
    "plt.xlabel('$\\gamma$', fontsize=35, color='black')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figures/stacked_figure_contribution_annotated_n_pv_%s.png'%(n_pv), dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TRANSACT_figures)",
   "language": "python",
   "name": "transact_figures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
