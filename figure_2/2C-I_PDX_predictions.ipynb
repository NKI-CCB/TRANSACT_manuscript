{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 2C-I : Drug response prediction from cell lines to PDX.\n",
    "This notebooks support Fig2 panel C to I and corresponds to the PDX prediction based on cell lines drug response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All list of import is in module_import.py\n",
    "from module_import import *\n",
    "from src_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data settings are in data_settings.py\n",
    "from data_settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = read_data(tissues=tissues,\n",
    "                    data_types=[e for e in data_types],\n",
    "                    projects=projects,\n",
    "                    data_sources=data_sources,\n",
    "                    folder_basis='../data/')\n",
    "\n",
    "source_data_key, target_data_key = reformat_df(data_df, source, target)\n",
    "\n",
    "data_df_combat = deepcopy(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library size normalization\n",
    "average_depth_global = 10**5\n",
    "for ds in list(data_df.keys()):\n",
    "    GE_normalized = library_size_normalization.TMM_normalization(data_df[ds].values.astype(float))\n",
    "    GE_normalized = np.array(GE_normalized)\n",
    "    average_depths = np.mean(np.sum(GE_normalized,1))\n",
    "    data_df_combat[ds] = pd.DataFrame(np.log(np.array(GE_normalized)+1),\n",
    "                                     columns=data_df_combat[ds].columns,\n",
    "                                     index=data_df_combat[ds].index)\n",
    "    GE_normalized = GE_normalized / average_depths * average_depth_global\n",
    "    GE_normalized = np.log(np.array(GE_normalized)+1)\n",
    "    data_df[ds] = pd.DataFrame(GE_normalized,\n",
    "                               columns=data_df[ds].columns,\n",
    "                               index=data_df[ds].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing genes for ComBat\n",
    "number_top_genes = 1700\n",
    "\n",
    "top_source_variable_genes = pd.DataFrame(np.var(data_df[source_data_key]), columns=['variance'])\n",
    "top_source_variable_genes = top_source_variable_genes.sort_values('variance', ascending=False)\n",
    "top_source_variable_genes = top_source_variable_genes.head(number_top_genes).index\n",
    "top_target_variable_genes = pd.DataFrame(np.var(data_df[target_data_key]), columns=['variance'])\n",
    "top_target_variable_genes = top_target_variable_genes.sort_values('variance', ascending=False)\n",
    "top_target_variable_genes = top_target_variable_genes.head(number_top_genes).index\n",
    "top_variable_genes = np.intersect1d(top_source_variable_genes, top_target_variable_genes)\n",
    "print(top_variable_genes.shape)\n",
    "\n",
    "for d in data_df:\n",
    "    data_df_combat[d] = data_df_combat[d][top_variable_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data_df = {\n",
    "    ds : StandardScaler(with_mean=with_mean, with_std=with_std).fit_transform(data_df[ds])\n",
    "    for ds in data_df\n",
    "}\n",
    "\n",
    "for ds in normalized_data_df:\n",
    "    normalized_data_df[ds] = pd.DataFrame(normalized_data_df[ds],\n",
    "                                         index=data_df[ds].index,\n",
    "                                         columns=data_df[ds].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drug response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDSC\n",
    "unique_drugs = None\n",
    "GDSC_drug_response_frames = {}\n",
    "for x in ['GDSC2', 'GDSC1']:\n",
    "    GDSC_drug_response_file = '../data/GDSC/response/%s_fitted_dose_response_25Feb20.xlsx'%(x)\n",
    "    GDSC_drug_response_frames[x] = pd.read_excel(GDSC_drug_response_file)\n",
    "    if unique_drugs is None:\n",
    "        unique_drugs = np.unique(GDSC_drug_response_frames[x]['DRUG_NAME'])\n",
    "    else:\n",
    "        unique_drugs = np.concatenate([unique_drugs, np.unique(GDSC_drug_response_frames[x]['DRUG_NAME'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDX\n",
    "PDX_drug_response_df = pd.read_csv('../data/PDXE/response/response.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment settings\n",
    "### Different similarity functions to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALl experimental settings are in expt_settings.py\n",
    "from expt_settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load drug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential pairs:\n",
    "#     ('Erlotinib', 'erlotinib'),\n",
    "#     ('Cetuximab', 'cetuximab'),\n",
    "#     ('Gemcitabine', 'gemcitabine-50mpk'),\n",
    "#     ('Afatinib', 'trastuzumab'),\n",
    "#     ('Paclitaxel', 'paclitaxel'),\n",
    "#     ('Trametinib', 'trametinib'),\n",
    "#     ('Ruxolitinib', 'INC424'),\n",
    "GDSC_drug_name, PDXE_drug_name = ('Erlotinib', 'erlotinib')\n",
    "\n",
    "drug_folder_name = 'response_GDSC_%s_PDXE_%s'%(GDSC_drug_name, PDXE_drug_name)\n",
    "if drug_folder_name not in os.listdir('./figures/'):\n",
    "    os.mkdir('./figures/'+drug_folder_name)\n",
    "drug_folder_name = './figures/'+drug_folder_name\n",
    "\n",
    "\n",
    "X_target_response, y_target = read_PDXE_response(PDX_drug_response_df,\n",
    "                                                 PDXE_drug_name,\n",
    "                                                 normalized_data_df[target_data_key])\n",
    "X_source_response, y_source = read_GDSC_response(GDSC_drug_response_frames,\n",
    "                                                 GDSC_drug_name,\n",
    "                                                 normalized_data_df[source_data_key])\n",
    "\n",
    "X_target_response_combat, y_target_combat = read_PDXE_response(PDX_drug_response_df,\n",
    "                                                               PDXE_drug_name,\n",
    "                                                               data_df_combat[target_data_key])\n",
    "X_source_response_combat, y_source_combat = read_GDSC_response(GDSC_drug_response_frames,\n",
    "                                                               GDSC_drug_name,\n",
    "                                                               data_df_combat[source_data_key])\n",
    "\n",
    "combat_cv_folder = output_combat_cv_folder + GDSC_drug_name\n",
    "uncorrected_cv_folder = GDSC_drug_name + ('_centered' if with_mean else '') + ('_standardized' if with_std else '')\n",
    "uncorrected_cv_folder = output_uncorrected_cv_folder + uncorrected_cv_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for various values of similarities and baselines\n",
    "### Import CV deep network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrected_param = read_best_param(uncorrected_cv_folder, random_state, 'uncorrected_cv_results.csv')\n",
    "combat_param = read_best_param(combat_cv_folder, random_state, 'combat_cv_results.csv')\n",
    "\n",
    "combat_param['n_input'] = data_df_combat[source_data_key].shape[1]\n",
    "uncorrected_param['n_input'] = data_df[source_data_key].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrected_network = make_network(uncorrected_param)\n",
    "uncorrected_network = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=with_mean, with_std=with_std)),\n",
    "    ('regression', make_skorch_network(uncorrected_network, uncorrected_param))\n",
    "])\n",
    "\n",
    "combat_network = make_network(combat_param)\n",
    "combat_network = make_skorch_network(combat_network, combat_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_PDX_spearman_cor(n_jobs=20, verbose=0, return_clf=False):\n",
    "    \"\"\"\n",
    "    This function performs all the comparisons, i.e. for all possible classifiers:\n",
    "        - Train on GDSC.\n",
    "        - Apply on PDXE.\n",
    "        - Compare the predicted PDXE response to the actual Best Average Response.\n",
    "    Different routines are used per classifier, which can be classified in 3 categories:\n",
    "        - Native scikit-learn: ElasticNet and KRR (Kernel Ridge Regression).\n",
    "        - Skorch: ComBat+DL and DL.\n",
    "        - Domain adaptation: PRECISE and TRANSACT.\n",
    "    For KRR and TRANSACT, one classifier is created per similarity function.\n",
    "    \"\"\"\n",
    "    target_spearman = {}\n",
    "    \n",
    "    if return_clf:\n",
    "        classifiers = {}\n",
    "        \n",
    "    for sim_surname, sim_name in zip(kernel_surnames, kernel_names):\n",
    "        #For each kernel:\n",
    "        #    - compute consensus features and project bootstrapped data on them,\n",
    "        #    - train predictive model based on bootstrapped labels,\n",
    "        #    - predict on target and save spearman correlation.\n",
    "        print(sim_surname)\n",
    "        clf = TRANSACT(kernel=sim_name,\n",
    "                      kernel_params=kernel_param[sim_surname],\n",
    "                      n_components=number_pc,\n",
    "                      n_jobs=n_jobs,\n",
    "                      verbose=verbose)\n",
    "        \n",
    "        clf.fit(normalized_data_df[source_data_key],\n",
    "                normalized_data_df[target_data_key],\n",
    "                n_pv=n_pv[sim_surname],\n",
    "                step=n_interpolation,\n",
    "                with_interpolation=True)\n",
    "\n",
    "        clf.fit_predictor(X_source_response, y_source.values.flatten(), l1_ratio=0.)\n",
    "        y_target_subsample_predicted = clf.predict(X_target_response)\n",
    "        target_spearman[sim_surname] = scipy.stats.spearmanr(y_target_subsample_predicted,\n",
    "                                                             y_target['BestAvgResponse'])\n",
    "        if return_clf:\n",
    "            classifiers[sim_surname] = deepcopy(clf)\n",
    "        \n",
    "    # Comparison to baseline\n",
    "    print('raw')\n",
    "    alpha_values = np.logspace(-5,10,16)\n",
    "    l1_ratio_values = np.linspace(1,10,11)/10\n",
    "    param_grid ={\n",
    "        'regression__alpha': alpha_values,\n",
    "        'regression__l1_ratio': l1_ratio_values\n",
    "    }\n",
    "    grid_raw = GridSearchCV(Pipeline([\n",
    "                            ('scaler', StandardScaler(with_mean=with_mean, with_std=with_std)),\n",
    "                            ('regression', ElasticNet())\n",
    "                            ]),\n",
    "                            cv=10, \n",
    "                            n_jobs=n_jobs, \n",
    "                            param_grid=param_grid, \n",
    "                            verbose=verbose, \n",
    "                            scoring='neg_mean_squared_error')\n",
    "    grid_raw.fit(X_source_response, y_source.values.flatten())\n",
    "    y_target_subsample_predicted = grid_raw.predict(X_target_response)\n",
    "    target_spearman['uncorrected_EN'] = scipy.stats.spearmanr(y_target_subsample_predicted,\n",
    "                                                        y_target['BestAvgResponse'])\n",
    "    classifiers['raw'] = grid_raw\n",
    "    \n",
    "    # Neural network without correction\n",
    "    print('Neural network uncorrected')\n",
    "    uncorrected_network.fit(X_source_response.values.astype(np.float32), y_source.values.astype(np.float32))\n",
    "    y_target_subsample_predicted = uncorrected_network.predict(X_target_response.values.astype(np.float32)).flatten()\n",
    "    target_spearman['uncorrected_network'] = scipy.stats.spearmanr(y_target_subsample_predicted,\n",
    "                                                                   y_target['BestAvgResponse'].values.flatten())\n",
    "    classifiers['uncorrected_network'] = uncorrected_network\n",
    "    \n",
    "    # Neural network without correction\n",
    "    print('Neural network with ComBat')\n",
    "    combat_network.fit(X_source_response_combat.values.astype(np.float32),\n",
    "                       y_source_combat.values.astype(np.float32))\n",
    "    y_target_subsample_predicted = combat_network.predict(X_target_response_combat.values.astype(np.float32)).flatten()\n",
    "    target_spearman['combat_network'] = scipy.stats.spearmanr(y_target_subsample_predicted,\n",
    "                                                                   y_target['BestAvgResponse'].values.flatten())\n",
    "    classifiers['combat_network'] = combat_network\n",
    "    \n",
    "    if return_clf:\n",
    "        return target_spearman, classifiers\n",
    "    return target_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs=30\n",
    "\n",
    "correlations_per_sim, clfs = predict_PDX_spearman_cor(n_jobs=n_jobs, verbose=0, return_clf=True)\n",
    "saving_id = str(uuid.uuid4())[:8]\n",
    "dump(correlations_per_sim, '%s/prediction_%s.csv'%(drug_folder_name,\n",
    "                                                   saving_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_file = os.listdir(drug_folder_name)\n",
    "potential_file = [p for p in potential_file if 'prediction' in p]\n",
    "if len(potential_file) == 1:\n",
    "    file = potential_file[0]\n",
    "else:\n",
    "    print('MORE THAN ONE FILE')\n",
    "    print(potential_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'prediction_122e8b39.csv'\n",
    "saving_id = re.search(r'_([0-9a-z]*).csv', file).group(1)\n",
    "correlations_per_sim = load(open(drug_folder_name + '/' + file, 'rb'))\n",
    "del file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot_df = pd.DataFrame(correlations_per_sim)\n",
    "to_plot_df = to_plot_df.T\n",
    "to_plot_df.columns = ['cor', 'p-val']\n",
    "to_plot_df = to_plot_df.loc[order]\n",
    "to_plot_df.index = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yticks = np.arange(0,8) / 10\n",
    "yticks_labels = [str(y) for y in yticks]\n",
    "colors = [mpl.colors.TABLEAU_COLORS['tab:gray']] * 4 + \\\n",
    "          [mpl.colors.TABLEAU_COLORS['tab:olive']] * 20\n",
    "\n",
    "plt.figure(figsize=(8,9))\n",
    "bplot = sns.barplot(data=to_plot_df.reset_index(),\n",
    "                    x='index',\n",
    "                    y='cor',\n",
    "                    order=labels,\n",
    "                    palette=colors, alpha=1.)\n",
    "\n",
    "plt.xlabel(None)\n",
    "plt.xticks(fontsize=25, color='black', rotation=90, fontproperties=prop_label)\n",
    "plt.ylim(0,0.7)\n",
    "plt.yticks(yticks, yticks_labels, fontsize=25, fontproperties=prop_ticks, color='black')\n",
    "plt.ylabel('Spearman correlation on PDXs', fontsize=25, color='black', fontproperties=prop_label)\n",
    "plt.tight_layout()\n",
    "plt.savefig('%s/results_%s.png'%(drug_folder_name, saving_id), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TRANSACT_figures)",
   "language": "python",
   "name": "transact_figures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
