{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 2C-I : Drug response prediction from cell lines to PDX.\n",
    "This notebooks support Fig2 panel C to I and corresponds to the PDX prediction based on cell lines drug response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "import scipy\n",
    "from copy import deepcopy\n",
    "import uuid\n",
    "from pickle import load, dump\n",
    "import re\n",
    "from datetime import date\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context('paper')\n",
    "from matplotlib import font_manager as fm, rcParams\n",
    "fpath = os.path.join(rcParams[\"datapath\"], \"fonts/ttf/arial.ttf\")\n",
    "prop_label = fm.FontProperties(fname=fpath)\n",
    "prop_label.set_size(30)\n",
    "prop_ticks = fm.FontProperties(fname=fpath)\n",
    "prop_ticks.set_size(25)\n",
    "fname = os.path.split(fpath)[1]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle, resample\n",
    "from joblib import dump, load, Parallel, delayed\n",
    "from statannot.statannot import add_stat_annotation\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from skorch import NeuralNetClassifier, NeuralNetRegressor\n",
    "\n",
    "sys.path.insert(0, '../read_data/')\n",
    "from read_data import read_data\n",
    "from read_GDSC_response import read_GDSC_response\n",
    "from read_PDXE_response import read_PDXE_response\n",
    "from reformat_df import reformat_df\n",
    "import library_size_normalization\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "from clf_utils import make_network\n",
    "\n",
    "from transact.pv_computation import PVComputation\n",
    "from transact.interpolation import Interpolation\n",
    "from transact.matrix_operations import _center_kernel, _right_center_kernel, _left_center_kernel\n",
    "from transact.kernel_computer import KernelComputer\n",
    "from transact.TRANSACT import TRANSACT\n",
    "\n",
    "from compute_proportion import compute_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "with_mean = True\n",
    "with_std = True\n",
    "\n",
    "# domain adaptation\n",
    "tissues = {\n",
    "    'PDXE': ['All'],\n",
    "    'GDSC': ['All']\n",
    "}\n",
    "projects = {\n",
    "    'PDXE':[None],\n",
    "    'GDSC': None\n",
    "}\n",
    "\n",
    "data_sources = ['GDSC', 'PDXE']\n",
    "\n",
    "data_types = ['fpkm']\n",
    "genes_filtering = 'mini'\n",
    "data_normalization = 'library_size' # Can be TPM, \"library_size\" or \"log\". Else will not have any influence.\n",
    "\n",
    "source = 'GDSC'\n",
    "target = 'PDXE'\n",
    "\n",
    "# Folder where CV has been saved\n",
    "output_combat_cv_folder = ''\n",
    "output_uncorrected_cv_folder = ''\n",
    "random_state = 183627362"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = read_data(tissues=tissues,\n",
    "                    data_types=[e for e in data_types],\n",
    "                    projects=projects,\n",
    "                    data_sources=data_sources,\n",
    "                    folder_basis='../data/')\n",
    "\n",
    "source_data_key, target_data_key = reformat_df(data_df, source, target)\n",
    "\n",
    "data_df_combat = deepcopy(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library size normalization\n",
    "average_depth_global = 10**5\n",
    "for ds in list(data_df.keys()):\n",
    "    GE_normalized = library_size_normalization.TMM_normalization(data_df[ds].values.astype(float))\n",
    "    GE_normalized = np.array(GE_normalized)\n",
    "    average_depths = np.mean(np.sum(GE_normalized,1))\n",
    "    data_df_combat[ds] = pd.DataFrame(np.log(np.array(GE_normalized)+1),\n",
    "                                     columns=data_df_combat[ds].columns,\n",
    "                                     index=data_df_combat[ds].index)\n",
    "    GE_normalized = GE_normalized / average_depths * average_depth_global\n",
    "    GE_normalized = np.log(np.array(GE_normalized)+1)\n",
    "    data_df[ds] = pd.DataFrame(GE_normalized,\n",
    "                               columns=data_df[ds].columns,\n",
    "                               index=data_df[ds].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing genes for ComBat\n",
    "number_top_genes = 1700\n",
    "\n",
    "top_source_variable_genes = pd.DataFrame(np.var(data_df[source_data_key]), columns=['variance'])\n",
    "top_source_variable_genes = top_source_variable_genes.sort_values('variance', ascending=False)\n",
    "top_source_variable_genes = top_source_variable_genes.head(number_top_genes).index\n",
    "top_target_variable_genes = pd.DataFrame(np.var(data_df[target_data_key]), columns=['variance'])\n",
    "top_target_variable_genes = top_target_variable_genes.sort_values('variance', ascending=False)\n",
    "top_target_variable_genes = top_target_variable_genes.head(number_top_genes).index\n",
    "top_variable_genes = np.intersect1d(top_source_variable_genes, top_target_variable_genes)\n",
    "print(top_variable_genes.shape)\n",
    "\n",
    "for d in data_df:\n",
    "    data_df_combat[d] = data_df_combat[d][top_variable_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data_df = {\n",
    "    ds : StandardScaler(with_mean=with_mean, with_std=with_std).fit_transform(data_df[ds])\n",
    "    for ds in data_df\n",
    "}\n",
    "\n",
    "for ds in normalized_data_df:\n",
    "    normalized_data_df[ds] = pd.DataFrame(normalized_data_df[ds],\n",
    "                                         index=data_df[ds].index,\n",
    "                                         columns=data_df[ds].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drug response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDSC\n",
    "unique_drugs = None\n",
    "GDSC_drug_response_frames = {}\n",
    "for x in ['GDSC2', 'GDSC1']:\n",
    "    GDSC_drug_response_file = '../data/GDSC/response/%s_fitted_dose_response_25Feb20.xlsx'%(x)\n",
    "    GDSC_drug_response_frames[x] = pd.read_excel(GDSC_drug_response_file)\n",
    "    if unique_drugs is None:\n",
    "        unique_drugs = np.unique(GDSC_drug_response_frames[x]['DRUG_NAME'])\n",
    "    else:\n",
    "        unique_drugs = np.concatenate([unique_drugs, np.unique(GDSC_drug_response_frames[x]['DRUG_NAME'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDX\n",
    "PDX_drug_response_df = pd.read_csv('../data/PDXE/response/response.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment settings\n",
    "### Different similarity functions to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_surnames = ['linear_centered_standardized',\n",
    "                   'rbf_gamma_1_centered_standardized',\n",
    "                   'rbf_gamma_2_centered_standardized',\n",
    "                   'rbf_gamma_3_centered_standardized',\n",
    "                   'rbf_gamma_4_centered_standardized',\n",
    "                   'rbf_gamma_5_centered_standardized',\n",
    "                   'rbf_gamma_6_centered_standardized',\n",
    "                   'rbf_gamma_7_centered_standardized'\n",
    "                  ]\n",
    "\n",
    "order = [\n",
    "    'uncorrected_EN',\n",
    "    'uncorrected_network',\n",
    "    'combat_network',\n",
    "    'linear_centered_standardized',\n",
    "    'rbf_gamma_1_centered_standardized',\n",
    "    'rbf_gamma_2_centered_standardized',\n",
    "    'rbf_gamma_3_centered_standardized',\n",
    "    'rbf_gamma_4_centered_standardized',\n",
    "    'rbf_gamma_5_centered_standardized',\n",
    "    'rbf_gamma_6_centered_standardized',\n",
    "    'rbf_gamma_7_centered_standardized'\n",
    "]\n",
    "labels = [\n",
    "    'Elastic Net',\n",
    "    'DL',\n",
    "    'ComBat + DL',\n",
    "    'PRECISE',\n",
    "    r'$\\gamma$=1$\\times$$10^{-5}$',\n",
    "    r'$\\gamma$=3$\\times$$10^{-5}$',\n",
    "    r'$\\gamma$=1$\\times$$10^{-4}$',\n",
    "    r'$\\gamma$=3$\\times$$10^{-4}$',\n",
    "    r'$\\gamma$=1$\\times$$10^{-3}$',\n",
    "    r'$\\gamma$=3$\\times$$10^{-3}$',\n",
    "    r'$\\gamma$=1$\\times$$10^{-2}$',\n",
    "]\n",
    "\n",
    "\n",
    "kernel_names = ['linear', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf']\n",
    "kernel_param = [\n",
    "    {},\n",
    "    {'gamma': 10**(-5)},\n",
    "    {'gamma': 10**(-4.5)},\n",
    "    {'gamma': 10**(-4)},\n",
    "    {'gamma': 10**(-3.5)},\n",
    "    {'gamma': 10**(-3)},\n",
    "    {'gamma': 10**(-2.5)},\n",
    "    {'gamma': 10**(-2)}\n",
    "]\n",
    "\n",
    "\n",
    "kernel_param = {k:p for k,p in zip(kernel_surnames, kernel_param)}\n",
    "\n",
    "number_pc = {\n",
    "    'source': 70,\n",
    "    'target': 50\n",
    "}\n",
    "\n",
    "n_pv = [20, 20, 20, 20, 20, 20, 20, 20]\n",
    "n_pv = {k:p for k,p in zip(kernel_surnames, n_pv)}\n",
    "n_interpolation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load drug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential pairs:\n",
    "#     ('Erlotinib', 'erlotinib'),\n",
    "#     ('Cetuximab', 'cetuximab'),\n",
    "#     ('Gemcitabine', 'gemcitabine-50mpk'),\n",
    "#     ('Afatinib', 'trastuzumab'),\n",
    "#     ('Paclitaxel', 'paclitaxel'),\n",
    "#     ('Trametinib', 'trametinib'),\n",
    "#     ('Ruxolitinib', 'INC424'),\n",
    "GDSC_drug_name, PDXE_drug_name = ('Ruxolitinib', 'INC424')\n",
    "\n",
    "drug_folder_name = 'response_GDSC_%s_PDXE_%s'%(GDSC_drug_name, PDXE_drug_name)\n",
    "if drug_folder_name not in os.listdir('./figures/'):\n",
    "    os.mkdir('./figures/'+drug_folder_name)\n",
    "drug_folder_name = './figures/'+drug_folder_name\n",
    "\n",
    "\n",
    "X_target_response, y_target = read_PDXE_response(PDX_drug_response_df,\n",
    "                                                 PDXE_drug_name,\n",
    "                                                 normalized_data_df[target_data_key])\n",
    "X_source_response, y_source = read_GDSC_response(GDSC_drug_response_frames,\n",
    "                                                 GDSC_drug_name,\n",
    "                                                 normalized_data_df[source_data_key])\n",
    "\n",
    "X_target_response_combat, y_target_combat = read_PDXE_response(PDX_drug_response_df,\n",
    "                                                               PDXE_drug_name,\n",
    "                                                               data_df_combat[target_data_key])\n",
    "X_source_response_combat, y_source_combat = read_GDSC_response(GDSC_drug_response_frames,\n",
    "                                                               GDSC_drug_name,\n",
    "                                                               data_df_combat[source_data_key])\n",
    "\n",
    "combat_cv_folder = output_combat_cv_folder + GDSC_drug_name\n",
    "uncorrected_cv_folder = GDSC_drug_name + ('_centered' if with_mean else '') + ('_standardized' if with_std else '')\n",
    "uncorrected_cv_folder = output_uncorrected_cv_folder + uncorrected_cv_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for various values of similarities and baselines\n",
    "### Import CV deep network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['hidden', 'input', 'activation', 'hiddenDO', 'inputDO', 'l2pen', 'lr']\n",
    "def parse_folder_results(f, folder):\n",
    "    param = {}\n",
    "    for n in param_names:\n",
    "        param[n] = re.search('%s_([0-9A-Za-z-.]+)'%(n), f)\n",
    "        param[n] = [param[n].group(1)] if param[n] else ''\n",
    "    param['folder'] = f\n",
    "    param_df = pd.DataFrame.from_dict(param)\n",
    "    \n",
    "    results_files = ['%s/%s/'%(folder, f) + e for e in os.listdir('%s/%s'%(folder, f))\n",
    "                     if '.csv' in e and 'pred_perf' in e and (str(random_state) in e or random_state is None)]\n",
    "    \n",
    "    if len(results_files) == 0:\n",
    "        return None\n",
    "    \n",
    "    results_df = [pd.read_csv(r, header=0, index_col=0) for r in results_files]\n",
    "    results_df = pd.concat(results_df)\n",
    "    results_df.index = [f] * results_df.shape[0]\n",
    "        \n",
    "    return results_df\n",
    "\n",
    "def read_best_param(folder, output_fig=None):\n",
    "    relevant_subfolders = [e for e in os.listdir(folder)\n",
    "                           if 'hidden' in e]\n",
    "\n",
    "    results_df = [parse_folder_results(f, folder)\n",
    "                              for f in relevant_subfolders]\n",
    "    results_df = [df for df in results_df if df is not None]\n",
    "    results_df = pd.concat(results_df)\n",
    "\n",
    "    baseline_df = pd.read_csv('%s/baseline_pred_perf_random-state_%s.csv'%(folder,\n",
    "                                                                           random_state),\n",
    "                              header=0, index_col=0)\n",
    "\n",
    "    results_df.columns = [('model', e) for e in results_df.columns]\n",
    "    for e in ['MSE', 'pred_perf']:\n",
    "        results_df[('baseline', e)] = baseline_df[e].values[0]\n",
    "    results_df.columns = pd.MultiIndex.from_tuples(results_df.columns)\n",
    "\n",
    "    if output_fig is not None:\n",
    "        results_df.to_csv('%s/%s'%(drug_folder_name, output_fig))\n",
    "    \n",
    "    best_model = results_df.sort_values(('model', 'pred_perf'), ascending=False).index[0]\n",
    "    best_model_param = folder + '/' + best_model + '/param.pkl'\n",
    "    best_model_param = load(open(best_model_param, 'rb'))\n",
    "    return best_model_param\n",
    "\n",
    "def make_skorch_network(net, param):\n",
    "    return NeuralNetRegressor(\n",
    "        net,\n",
    "        max_epochs=param['n_epochs'],\n",
    "        lr=param['learning_rate'],\n",
    "        batch_size=param['batch_size'],\n",
    "        device= 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        optimizer=torch.optim.SGD,\n",
    "        optimizer__momentum=param['momentum'],\n",
    "        optimizer__weight_decay=param['l2_penalty'],\n",
    "        iterator_train__shuffle = True,\n",
    "        verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrected_param = read_best_param(uncorrected_cv_folder, 'uncorrected_cv_results.csv')\n",
    "combat_param = read_best_param(combat_cv_folder, 'combat_cv_results.csv')\n",
    "\n",
    "combat_param['n_input'] = data_df_combat[source_data_key].shape[1]\n",
    "uncorrected_param['n_input'] = data_df[source_data_key].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrected_network = make_network(uncorrected_param)\n",
    "uncorrected_network = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=with_mean, with_std=with_std)),\n",
    "    ('regression', make_skorch_network(uncorrected_network, uncorrected_param))\n",
    "])\n",
    "\n",
    "combat_network = make_network(combat_param)\n",
    "combat_network = make_skorch_network(combat_network, combat_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_PDX_spearman_cor(n_jobs=20, verbose=0, return_clf=False):\n",
    "    target_spearman = {}\n",
    "    \n",
    "    if return_clf:\n",
    "        classifiers = {}\n",
    "        \n",
    "    for sim_surname, sim_name in zip(kernel_surnames, kernel_names):\n",
    "        #For each kernel:\n",
    "        #    - compute consensus features and project bootstrapped data on them,\n",
    "        #    - train predictive model based on bootstrapped labels,\n",
    "        #    - predict on target and save spearman correlation.\n",
    "        print(sim_surname)\n",
    "        clf = TRANSACT(kernel=sim_name,\n",
    "                      kernel_params=kernel_param[sim_surname],\n",
    "                      n_components=number_pc,\n",
    "                      n_jobs=n_jobs,\n",
    "                      verbose=verbose)\n",
    "        \n",
    "        clf.fit(normalized_data_df[source_data_key],\n",
    "                normalized_data_df[target_data_key],\n",
    "                n_pv=n_pv[sim_surname],\n",
    "                step=n_interpolation,\n",
    "                with_interpolation=True)\n",
    "\n",
    "        clf.fit_predictor(X_source_response, y_source.values.flatten(), l1_ratio=0.)\n",
    "        y_target_subsample_predicted = clf.predict(X_target_response)\n",
    "        target_spearman[sim_surname] = scipy.stats.spearmanr(y_target_subsample_predicted,\n",
    "                                                             y_target['BestAvgResponse'])\n",
    "        if return_clf:\n",
    "            classifiers[sim_surname] = deepcopy(clf)\n",
    "        \n",
    "    # Comparison to baseline\n",
    "    print('raw')\n",
    "    alpha_values = np.logspace(-5,10,16)\n",
    "    l1_ratio_values = np.linspace(1,10,11)/10\n",
    "    param_grid ={\n",
    "        'regression__alpha': alpha_values,\n",
    "        'regression__l1_ratio': l1_ratio_values\n",
    "    }\n",
    "    grid_raw = GridSearchCV(Pipeline([\n",
    "                            ('scaler', StandardScaler(with_mean=with_mean, with_std=with_std)),\n",
    "                            ('regression', ElasticNet())\n",
    "                            ]),\n",
    "                            cv=10, \n",
    "                            n_jobs=n_jobs, \n",
    "                            param_grid=param_grid, \n",
    "                            verbose=verbose, \n",
    "                            scoring='neg_mean_squared_error')\n",
    "    grid_raw.fit(X_source_response, y_source.values.flatten())\n",
    "    y_target_subsample_predicted = grid_raw.predict(X_target_response)\n",
    "    target_spearman['uncorrected_EN'] = scipy.stats.spearmanr(y_target_subsample_predicted,\n",
    "                                                        y_target['BestAvgResponse'])\n",
    "    classifiers['raw'] = grid_raw\n",
    "    \n",
    "    # Neural network without correction\n",
    "    print('Neural network uncorrected')\n",
    "    uncorrected_network.fit(X_source_response.values.astype(np.float32), y_source.values.astype(np.float32))\n",
    "    y_target_subsample_predicted = uncorrected_network.predict(X_target_response.values.astype(np.float32)).flatten()\n",
    "    target_spearman['uncorrected_network'] = scipy.stats.spearmanr(y_target_subsample_predicted,\n",
    "                                                                   y_target['BestAvgResponse'].values.flatten())\n",
    "    classifiers['uncorrected_network'] = uncorrected_network\n",
    "    \n",
    "    # Neural network without correction\n",
    "    print('Neural network with ComBat')\n",
    "    combat_network.fit(X_source_response_combat.values.astype(np.float32),\n",
    "                       y_source_combat.values.astype(np.float32))\n",
    "    y_target_subsample_predicted = combat_network.predict(X_target_response_combat.values.astype(np.float32)).flatten()\n",
    "    target_spearman['combat_network'] = scipy.stats.spearmanr(y_target_subsample_predicted,\n",
    "                                                                   y_target['BestAvgResponse'].values.flatten())\n",
    "    classifiers['combat_network'] = combat_network\n",
    "    \n",
    "    if return_clf:\n",
    "        return target_spearman, classifiers\n",
    "    return target_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs=30\n",
    "\n",
    "correlations_per_sim, clfs = predict_PDX_spearman_cor(n_jobs=n_jobs, verbose=0, return_clf=True)\n",
    "saving_id = str(uuid.uuid4())[:8]\n",
    "dump(correlations_per_sim, '%s/prediction_%s.csv'%(drug_folder_name,\n",
    "                                                   saving_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_file = os.listdir(drug_folder_name)\n",
    "potential_file = [p for p in potential_file if 'prediction' in p]\n",
    "if len(potential_file) == 1:\n",
    "    file = potential_file[0]\n",
    "else:\n",
    "    print('MORE THAN ONE FILE')\n",
    "    print(potential_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'prediction_122e8b39.csv'\n",
    "saving_id = re.search(r'_([0-9a-z]*).csv', file).group(1)\n",
    "correlations_per_sim = load(open(drug_folder_name + '/' + file, 'rb'))\n",
    "del file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot_df = pd.DataFrame(correlations_per_sim)\n",
    "to_plot_df = to_plot_df.T\n",
    "to_plot_df.columns = ['cor', 'p-val']\n",
    "to_plot_df = to_plot_df.loc[order]\n",
    "to_plot_df.index = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yticks = np.arange(0,8) / 10\n",
    "yticks_labels = [str(y) for y in yticks]\n",
    "colors = [mpl.colors.TABLEAU_COLORS['tab:gray']] * 4 + \\\n",
    "          [mpl.colors.TABLEAU_COLORS['tab:olive']] * 20\n",
    "\n",
    "plt.figure(figsize=(8,9))\n",
    "bplot = sns.barplot(data=to_plot_df.reset_index(),\n",
    "                    x='index',\n",
    "                    y='cor',\n",
    "                    order=labels,\n",
    "                    palette=colors, alpha=1.)\n",
    "\n",
    "plt.xlabel(None)\n",
    "plt.xticks(fontsize=25, color='black', rotation=90, fontproperties=prop_label)\n",
    "plt.ylim(0,0.7)\n",
    "plt.yticks(yticks, yticks_labels, fontsize=25, fontproperties=prop_ticks, color='black')\n",
    "plt.ylabel('Spearman correlation on PDXs', fontsize=25, color='black', fontproperties=prop_label)\n",
    "plt.tight_layout()\n",
    "plt.savefig('%s/results_%s.png'%(drug_folder_name, saving_id), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TRANSACT_figures)",
   "language": "python",
   "name": "transact_figures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
